{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f128a1a3-72ca-4357-ac82-47f1dcb483e9",
   "metadata": {},
   "source": [
    "# Baseline Model for Kaggel chaii competition.\n",
    "## In this competition we are suppose to predict Answer (index) given the question and context document\n",
    "## Data Language is Hindi and Tamil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f33cf7-7464-4c2b-a18b-2a1b66929f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (AutoTokenizer,AutoModelForQuestionAnswering,DataCollatorWithPadding)\n",
    "from transformers import get_scheduler\n",
    "from transformers import AdamW\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "## path for kaggel notebook\n",
    "# data_dir = '/kaggle/input/chaii-hindi-and-tamil-question-answering/'\n",
    "# output_dir = '/kaggle/output/kaggle/working/'\n",
    "\n",
    "\n",
    "data_dir = '/home/ubuntu/repo/chaii4deeplearningkaggler/data/'\n",
    "output_dir = data_dir+'outputs/'\n",
    "\n",
    "train_fn = 'train.csv'\n",
    "test_fn='test.csv'\n",
    "sub_fn = 'sample_submission.csv'\n",
    "\n",
    "BATCH_SIZE= 8\n",
    "## max length of padding and trunc\n",
    "MAX_LENGTH = 512\n",
    "lr = 5e-5\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a6035b4-207d-460c-9eb4-cec576060212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir+train_fn)\n",
    "test_df = pd.read_csv(data_dir+test_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ee9f8a5-7c45-4c26-a7c1-dfca95736502",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_id2idx = { eid:idx for idx,eid in enumerate(df['id'].values)}\n",
    "example_idx2id = { idx:eid for idx,eid in enumerate(df['id'].values)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73666692-7c7f-42a0-9f24-cbb406237090",
   "metadata": {},
   "source": [
    "# checking if give answer start (index) label is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5dca1ab-36ea-4cb0-92d2-8fb7804e8f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 token len of the corpus in training dataset: [10259, 9650, 8946, 8944, 8848, 8803, 8433, 8403, 8403, 7725]\n"
     ]
    }
   ],
   "source": [
    "corp_lens = []\n",
    "for idx in range(0,df.shape[0]):\n",
    "    subdf = df.iloc[idx]\n",
    "    strt = subdf['answer_start']\n",
    "    end = strt+len(subdf['answer_text'])\n",
    "    ans = subdf['context'][strt:end]\n",
    "    \n",
    "    corp_lens.append(len(subdf['context'].split()))\n",
    "    if not ans==subdf['answer_text']:\n",
    "        print(idx,ans,'****',subdf['answer_text'])\n",
    "        \n",
    "## This is very rough estimation of corpus length. It doesnt represent actual token lenght from tokenizer        \n",
    "print(f'top 10 token len of the corpus in training dataset: {sorted(corp_lens,reverse=True)[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff87e26-3fcc-4ea7-8a92-249cff730a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>language</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>903deec17</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206</td>\n",
       "      <td>53</td>\n",
       "      <td>tamil</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d9841668c</td>\n",
       "      <td>காளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...</td>\n",
       "      <td>காளிதாசன் எங்கு பிறந்தார்?</td>\n",
       "      <td>காசுமீரில்</td>\n",
       "      <td>2358</td>\n",
       "      <td>tamil</td>\n",
       "      <td>2368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29d154b56</td>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...</td>\n",
       "      <td>பென்சிலின் கண்டுபிடித்தவர் யார்?</td>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n",
       "      <td>0</td>\n",
       "      <td>tamil</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41660850a</td>\n",
       "      <td>குழந்தையின் அழுகையை  நிறுத்தவும், தூங்க வைக்கவ...</td>\n",
       "      <td>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...</td>\n",
       "      <td>தாலாட்டு</td>\n",
       "      <td>68</td>\n",
       "      <td>tamil</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b29c82c22</td>\n",
       "      <td>சூரியக் குடும்பம் \\nசூரியக் குடும்பம் (Solar S...</td>\n",
       "      <td>பூமியின் அருகில் உள்ள விண்மீன் எது?</td>\n",
       "      <td>சூரியனும்</td>\n",
       "      <td>585</td>\n",
       "      <td>tamil</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            context  \\\n",
       "0  903deec17  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   \n",
       "1  d9841668c  காளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...   \n",
       "2  29d154b56  சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...   \n",
       "3  41660850a  குழந்தையின் அழுகையை  நிறுத்தவும், தூங்க வைக்கவ...   \n",
       "4  b29c82c22  சூரியக் குடும்பம் \\nசூரியக் குடும்பம் (Solar S...   \n",
       "\n",
       "                                            question  \\\n",
       "0               மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "1                         காளிதாசன் எங்கு பிறந்தார்?   \n",
       "2                   பென்சிலின் கண்டுபிடித்தவர் யார்?   \n",
       "3  தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...   \n",
       "4                பூமியின் அருகில் உள்ள விண்மீன் எது?   \n",
       "\n",
       "                  answer_text  answer_start language  answer_end  \n",
       "0                         206            53    tamil          56  \n",
       "1                  காசுமீரில்          2358    tamil        2368  \n",
       "2  சர் அலெக்ஸாண்டர் ஃபிளெமிங்             0    tamil          26  \n",
       "3                    தாலாட்டு            68    tamil          76  \n",
       "4                   சூரியனும்           585    tamil         594  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## function to generate answer end using start index and answer\n",
    "def add_end_index(row):\n",
    "    strt = row['answer_start']\n",
    "    end = strt+len(row['answer_text'])\n",
    "    ans = row['context'][strt:end]\n",
    "    assert(ans==row['answer_text'])\n",
    "    return end\n",
    "df['answer_end'] = df.apply(add_end_index,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b27815-7af3-4a09-baaf-7c15743a3e0a",
   "metadata": {},
   "source": [
    "# Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3dcc648-4434-4bad-a72e-a88686d8963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(946, 7) (168, 7) (1114, 7)\n"
     ]
    }
   ],
   "source": [
    "## random shuffle and splitting data set\n",
    "## ratio is 85-15\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "split_idx = int(0.85*df.shape[0])\n",
    "train_df = df.iloc[:split_idx].reset_index(drop=True)\n",
    "valid_df = df.iloc[split_idx:].reset_index(drop=True)\n",
    "\n",
    "print(train_df.shape,valid_df.shape,df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3eb1f96-33b8-4379-b3c4-2356c1e73839",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating Dataset from pandas. This is hugging face dataset not pytorch\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "valid_dataset = Dataset.from_pandas(valid_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c4932-9af9-4a18-a83e-95ccb609907d",
   "metadata": {},
   "source": [
    "# Initializing the model and tokenizer using pretrain weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b22805b0-d882-4b04-99e3-b7bf173392a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertForQuestionAnswering: ['predictions.bias', 'predictions.dense.weight', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.bias', 'sop_classifier.classifier.weight', 'sop_classifier.classifier.bias', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForQuestionAnswering were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pretrain_path = 'ai4bharat/indic-bert'\n",
    "# pretrain_path = '/kaggle/input/indicbert/indic-bert-v1'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrain_path)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(pretrain_path)\n",
    "model = model.to(device)\n",
    "## data collator to prepare batch data\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4139b10c-579f-4c53-843c-39485105f4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of vocab our tokenizer have 200000\n",
      "printing ... few **vocab** ['▁পুঁজিবাদ', 'ുന്തോറും', '▁spur', 'వులను', '▁পদক্ষেপের', '▁ઓફીસ', '▁பலத்த', '▁বাংলাদেশিদের', 'ിലാ', '▁பொறி'] and their **index** [158243, 160427, 62651, 173786, 118925, 86150, 27947, 48624, 96248, 70064]\n"
     ]
    }
   ],
   "source": [
    "all_vocab = tokenizer.get_vocab()\n",
    "print(f'number of vocab our tokenizer have {len(all_vocab)}')\n",
    "print(f'printing ... few **vocab** {list(all_vocab.keys())[:10]} and their **index** {list(all_vocab.values())[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d226603-7a85-4700-b551-ebb648e36cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to create token out of each question and context pair.\n",
    "## context and question pair are concat together\n",
    "def dataprep(data):\n",
    "    data['question'] = [q.strip() for q in data['question']]\n",
    "    data['context'] = [c.strip() for c in data['context']]\n",
    "    \n",
    "    data_tokenizer = tokenizer(data['context'],\n",
    "                               data['question'],\n",
    "                               truncation='only_first',\n",
    "                               max_length=MAX_LENGTH)\n",
    "    \n",
    "    \n",
    "    data_tokenizer[\"start_positions\"] = [s for s in data['answer_start']]\n",
    "    data_tokenizer[\"end_positions\"] = [e for e in data['answer_end']]\n",
    "    data_tokenizer['example_id'] = [example_id2idx[i] for i in data['id']]\n",
    "    return data_tokenizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05aa8a09-6d19-4a4c-9abb-ebeba892fac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6cb453bc924813b10ea014b0db59be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ed7cc6a3d64f359afb748ac0c03d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## creating token using dataprep function\n",
    "tokenized_train_ds = train_dataset.map(dataprep,batched=True,remove_columns=train_dataset.column_names)\n",
    "tokenized_valid_ds = valid_dataset.map(dataprep,batched=True,remove_columns=valid_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7c34a7b-cbba-487c-af00-f08045747909",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_ds.set_format(\"torch\")\n",
    "tokenized_valid_ds.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f82b765d-0935-43b7-b2ab-ea0811cc548e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>end_positions</th>\n",
       "      <th>example_id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>start_positions</th>\n",
       "      <th>token_type_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>57</td>\n",
       "      <td>534</td>\n",
       "      <td>[2, 23269, 1134, 4761, 11611, 8430, 1134, 68, ...</td>\n",
       "      <td>44</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>124</td>\n",
       "      <td>396</td>\n",
       "      <td>[2, 1209, 19080, 20, 68508, 154664, 216, 79460...</td>\n",
       "      <td>109</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>555</td>\n",
       "      <td>873</td>\n",
       "      <td>[2, 3039, 9691, 5458, 25397, 1976, 1883, 130, ...</td>\n",
       "      <td>527</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1084</td>\n",
       "      <td>378</td>\n",
       "      <td>[2, 1500, 10495, 1301, 6511, 1883, 1539, 494, ...</td>\n",
       "      <td>1075</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>725</td>\n",
       "      <td>[2, 1883, 11339, 25272, 65990, 1546, 1134, 188...</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      attention_mask  end_positions  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...             57   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...            124   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...            555   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...           1084   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              8   \n",
       "\n",
       "   example_id                                          input_ids  \\\n",
       "0         534  [2, 23269, 1134, 4761, 11611, 8430, 1134, 68, ...   \n",
       "1         396  [2, 1209, 19080, 20, 68508, 154664, 216, 79460...   \n",
       "2         873  [2, 3039, 9691, 5458, 25397, 1976, 1883, 130, ...   \n",
       "3         378  [2, 1500, 10495, 1301, 6511, 1883, 1539, 494, ...   \n",
       "4         725  [2, 1883, 11339, 25272, 65990, 1546, 1134, 188...   \n",
       "\n",
       "   start_positions                                     token_type_ids  \n",
       "0               44  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1              109  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2              527  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3             1075  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4                5  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_ds.data.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63b0868a-16df-4097-b72a-a6ca53d4ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using pytorch DataLoader function \n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_train_ds, shuffle=True, batch_size=BATCH_SIZE, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_valid_ds, batch_size=BATCH_SIZE, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2da5ee2e-6d03-4949-ac6d-f13786684237",
   "metadata": {},
   "outputs": [],
   "source": [
    "## learning rate decay scheduler\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7a0fee9-7919-457c-a82f-3528a5da49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def jacard_score_(data_dict):\n",
    "    score = 0\n",
    "    for data in data_dict:\n",
    "        p,tp = list(data.values())[0]\n",
    "        if p is not '' and tp is not '':\n",
    "            score += jaccard(p,tp)\n",
    "    return score\n",
    "            \n",
    "## extracting answer from logits\n",
    "def postprocess(dataset,eid,slogits,elogits,spos,epos,idx2id,n_best_size=20,max_answer_length=30):\n",
    "    predictions = {}\n",
    "    for idx in range(len(slogits)):\n",
    "        start_logits = slogits[idx]\n",
    "        end_logits = elogits[idx]\n",
    "        tstart = spos[idx]\n",
    "        tend = epos[idx]\n",
    "        ## getting from pandas dataframe using id\n",
    "        data = dataset[dataset.id == idx2id[eid[idx].item()]]\n",
    "        ## selecting top 20 logits\n",
    "        start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "        end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "        valid_ans = []\n",
    "        corp = data['context'].values[0]\n",
    "        \n",
    "        ## iterating over each index pair and discarding invalid ones\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                \n",
    "                if end_index < start_index or end_index-start_index+1 > max_answer_length:\n",
    "                    continue\n",
    "                valid_ans.append({'score':start_logits[start_index]+end_logits[end_index],\n",
    "                 'text':corp[start_index:end_index]})\n",
    "        # selecting best answer        \n",
    "        if len(valid_ans) >0:\n",
    "            best_answer = sorted(valid_ans, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            best_answer = {\"text\": '', \"score\": 0.0}\n",
    "        ## predicting answer with true answer\n",
    "        \n",
    "        predictions[data['id'].values[0]] = [best_answer['text'],corp[int(tstart):int(tend)]]        \n",
    "    return [predictions]\n",
    "\n",
    "## evaluation \n",
    "def model_eval(model,evaldataset_,evaldf,idx2id):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    preds = []\n",
    "    n = len(evaldataset_)\n",
    "    for batch in evaldataset_:\n",
    "        batch_ = {k: v.to(device) for k, v in batch.items() if k != 'example_id'}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch_)\n",
    "        loss+= outputs.loss.item()\n",
    "        \n",
    "        slogits = outputs.start_logits.cpu().detach().numpy()\n",
    "        elogits = outputs.end_logits.cpu().detach().numpy()\n",
    "        spos = batch['start_positions']\n",
    "        epos = batch['end_positions']\n",
    "\n",
    "        preds.extend(postprocess(evaldf,batch['example_id'],slogits,elogits,spos,epos,idx2id))\n",
    "    jac_score = jacard_score_(preds)\n",
    "    print(f'valid loss is {loss/n} and jaccard score is {jac_score/n}')\n",
    "\n",
    "## training\n",
    "def train(model,traindata,evaldata,progress_steps,epochs):\n",
    "    progress_bar = tqdm(range(progress_steps))\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch in traindata:\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch_ = {k: v.to(device) for k, v in batch.items() if k != 'example_id'}\n",
    "            outputs = model(**batch_)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.update(1)\n",
    "        print(f'training loss for epoch {epoch} is {epoch_loss/len(traindata)}')\n",
    "        model_eval(model,evaldata[0],evaldata[1],example_idx2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6400f3e5-1a10-4313-bad0-8be087d1f68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58fe9bb7f754841b362befc894e98b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss for epoch 0 is 5.948097802009903\n",
      "valid loss is 5.945135411762056 and jaccard score is 0.08412698412698412\n"
     ]
    }
   ],
   "source": [
    "train(model,train_dataloader,[eval_dataloader,valid_df],num_training_steps,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3edd03b-bb36-44e6-9a5e-2ed12b2ae1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ca811dbddc4d999fe2f8a8037a4312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texample_id2idx = { eid:idx for idx,eid in enumerate(test_df['id'].values)}\n",
    "texample_idx2id = { idx:eid for idx,eid in enumerate(test_df['id'].values)}\n",
    "\n",
    "def testdataprep(data):\n",
    "    \n",
    "    data['question'] = [q.strip() for q in data['question']]\n",
    "    data['context'] = [c.strip() for c in data['context']]\n",
    "    \n",
    "    data_tokenizer = tokenizer(data['context'],\n",
    "                               data['question'],\n",
    "                               truncation='only_first',\n",
    "                               padding=\"max_length\",\n",
    "                               max_length=MAX_LENGTH)\n",
    "    data_tokenizer['example_id'] = [texample_id2idx[i] for i in data['id']]\n",
    "    return data_tokenizer\n",
    "\n",
    "\n",
    "tokenized_test_ds = test_dataset.map(testdataprep,batched=True,remove_columns=test_dataset.column_names)\n",
    "tokenized_test_ds.set_format(\"torch\")\n",
    "test_dataloader = DataLoader(tokenized_test_ds,collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9447c15-9f39-450a-8879-661e595b9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(predset,idx2id):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for batch in predset:\n",
    "        batch_ = {k: v.to(device) for k, v in batch.items() if k != 'example_id'}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch_)\n",
    "        \n",
    "        slogits = outputs.start_logits.cpu().detach().numpy()\n",
    "        elogits = outputs.end_logits.cpu().detach().numpy()\n",
    "        spos=epos =np.zeros(slogits.shape[0])\n",
    "        preds.extend(postprocess(test_df,batch['example_id'],slogits,elogits,spos,epos,idx2id))\n",
    "    return preds\n",
    "\n",
    "predictions =predict(test_dataloader,texample_idx2id)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eae9de52-b108-468e-821a-daebbafd4ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_sub(idx):\n",
    "    for p in predictions:\n",
    "        if idx in p:\n",
    "            return p[idx][0]\n",
    "test_df['PredictionString'] = test_df.id.apply(prep_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a16eea2a-a420-4b45-86f2-dd0cfabcf124",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop(columns=['context','question','language'], axis=1)\n",
    "test_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb614f0-5cfd-43eb-b9a0-01eacc07a817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_latest_p37]",
   "language": "python",
   "name": "conda-env-pytorch_latest_p37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
